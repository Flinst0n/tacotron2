{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tacotron 2 inference code \n",
    "Edit the variables **checkpoint_path** and **text** to match yours and run the entire code to generate plots of mel outputs, alignments and audio synthesis from the generated mel-spectrogram using Griffin-Lim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and setup matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "sys.path.append('waveglow-mirror/')\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "from denoiser import Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, figsize=(16, 4)):\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
    "    for i in range(len(data)):\n",
    "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
    "                       interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = create_hparams()\n",
    "hparams.sampling_rate = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"tacotron2_statedict.pt\"\n",
    "model = load_model(hparams)\n",
    "model.load_state_dict(torch.load(checkpoint_path,map_location='cpu')['state_dict'])\n",
    "_ = model.cpu().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load WaveGlow for mel2audio synthesis and denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveglow_path = 'waveglow_256channels.pt'\n",
    "waveglow = torch.load(waveglow_path,map_location='cpu')['model']\n",
    "waveglow.cpu().eval()\n",
    "for k in waveglow.convinv:\n",
    "    k.float()\n",
    "    \n",
    "for m in waveglow.modules():\n",
    "    if 'Conv' in str(type(m)):\n",
    "        setattr(m, 'padding_mode', 'zeros')\n",
    "        #print(m)\n",
    "\n",
    "#denoiser = Denoiser(waveglow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "text = \"Hi Paul! Waveglow is really awesome!\"\n",
    "sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cpu().long()\n",
    "\n",
    "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "\n",
    "with torch.no_grad():\n",
    "    audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Total calculation time %.2lf\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio[0])/hparams.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_texts(texts):\n",
    "  audios = None\n",
    "  \n",
    "  for text in texts:\n",
    "    start = time.time()\n",
    "    print(\"Calculating %s\" % (text[:10]))\n",
    "    sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "    sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cpu().long()\n",
    "\n",
    "    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
    "    end = time.time()\n",
    "        \n",
    "    if audios is not None:\n",
    "      audios = np.append(audios, audio[0].data.cpu().numpy())\n",
    "    else:\n",
    "      audios = audio[0].data.cpu().numpy()\n",
    "\n",
    "    \n",
    "    print(\"Total calculation time %.2lf, Length %.2lf, Real-Time: %.2lf\" % (end - start, len(audio[0])/hparams.sampling_rate, (end - start)/(len(audio[0])/hparams.sampling_rate)))\n",
    "      \n",
    "  return audios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"May I have your attention please?\", \"May I have your attention please?\", \"Will the real Slim Shady please stand up?\", \"I repeat, will the real Slim Shady please stand up?\", \"We're gonna have a problem here.\"] + [\"Cut my life into pieces.\",\n",
    "\"This is my last resort.\",\n",
    "\"Suffocation.\",\n",
    "\"No breathing.\",\n",
    "\"Don't give a fuck if I cut my arm bleeding.\",\n",
    "\"This is my last resort.\"]\n",
    "audios = generate_texts(texts)\n",
    "ipd.Audio(audios, rate=hparams.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"May I have your attention please?\", \"May I have your attention please?\", \"Will the real Slim Shady please stand up?\", \"I repeat, will the real Slim Shady please stand up?\", \"We're gonna have a problem here.\"] + [\"Cut my life into pieces.\",\n",
    "\"This is my last resort.\",\n",
    "\"Suffocation.\",\n",
    "\"No breathing.\",\n",
    "\"Don't give a fuck if I cut my arm bleeding.\",\n",
    "\"This is my last resort.\"]\n",
    "audios = generate_texts(texts)\n",
    "ipd.Audio(audios, rate=hparams.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Waveglow is really awesome!\"\n",
    "sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cpu().long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode text input and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
    "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "           alignments.float().data.cpu().numpy()[0].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthesize audio from spectrogram using WaveGlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
    "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Remove WaveGlow bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_denoised = denoiser(audio, strength=0.01)[:, 0]\n",
    "ipd.Audio(audio_denoised.cpu().numpy(), rate=hparams.sampling_rate) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
